# script to extract and tidy tube temperatures csv
# function to extract data from url -----------------------------------------------
download_url <- function(url, fileext) {
tempdir <- tempdir()
path <- tempfile(tmpdir = tempdir, fileext = fileext)
download.file(url, destfile = path, mode = "wb")
path
}
# extract data --------------------------------------------------------------------
url <- "https://data.london.gov.uk/download/london-underground-average-monthly-temperatures/b01c7853-fff2-4781-9755-9b5e1404d78c/lu-average-monthly-temperatures.csv" # url for tube temp data download
tube_temps <- read_csv(download_url(url, ".csv"))
# data tidying --------------------------------------------------------------------
tube_temps %>%
left_join(months, by = "Month") %>%
mutate(date = as.Date(paste("01", month_num, Year, sep = "/"), "%d/%m/%Y")) %>%
select(-month_num) %>%
gather(Bakerloo:`Sub-surface_lines`, key = "tube", value = "temperature") %>%
mutate(tube = ifelse(tube == "Sub-surface_lines", "Sub-Surface Lines", tube)) %>%
mutate(tube = ifelse(tube == "Waterloo_and_City", "Waterloo and City", tube))
# save clean data to csv ----------------------------------------------------------
write.csv(tube_temps, "output-data/tube_temps.csv", row.names = FALSE)
# script to extract and tidy tube temperatures csv
# libs ----------------------------------------------------------------------------
library(tidyselect)
# function to extract data from url -----------------------------------------------
download_url <- function(url, fileext) {
tempdir <- tempdir()
path <- tempfile(tmpdir = tempdir, fileext = fileext)
download.file(url, destfile = path, mode = "wb")
path
}
# extract data --------------------------------------------------------------------
url <- "https://data.london.gov.uk/download/london-underground-average-monthly-temperatures/b01c7853-fff2-4781-9755-9b5e1404d78c/lu-average-monthly-temperatures.csv" # url for tube temp data download
tube_temps <- read_csv(download_url(url, ".csv"))
# data tidying --------------------------------------------------------------------
tube_temps %>%
left_join(months, by = "Month") %>%
mutate(date = as.Date(paste("01", month_num, Year, sep = "/"), "%d/%m/%Y")) %>%
select(-month_num) %>%
gather(Bakerloo:`Sub-surface_lines`, key = "tube", value = "temperature") %>%
mutate(tube = ifelse(tube == "Sub-surface_lines", "Sub-Surface Lines", tube)) %>%
mutate(tube = ifelse(tube == "Waterloo_and_City", "Waterloo and City", tube))
# save clean data to csv ----------------------------------------------------------
write.csv(tube_temps, "output-data/tube_temps.csv", row.names = FALSE)
# script to extract and tidy tube temperatures csv
# libs ----------------------------------------------------------------------------
library(tidyverse)
# function to extract data from url -----------------------------------------------
download_url <- function(url, fileext) {
tempdir <- tempdir()
path <- tempfile(tmpdir = tempdir, fileext = fileext)
download.file(url, destfile = path, mode = "wb")
path
}
# extract data --------------------------------------------------------------------
url <- "https://data.london.gov.uk/download/london-underground-average-monthly-temperatures/b01c7853-fff2-4781-9755-9b5e1404d78c/lu-average-monthly-temperatures.csv" # url for tube temp data download
tube_temps <- read_csv(download_url(url, ".csv"))
# data tidying --------------------------------------------------------------------
tube_temps %>%
left_join(months, by = "Month") %>%
mutate(date = as.Date(paste("01", month_num, Year, sep = "/"), "%d/%m/%Y")) %>%
select(-month_num) %>%
gather(Bakerloo:`Sub-surface_lines`, key = "tube", value = "temperature") %>%
mutate(tube = ifelse(tube == "Sub-surface_lines", "Sub-Surface Lines", tube)) %>%
mutate(tube = ifelse(tube == "Waterloo_and_City", "Waterloo and City", tube))
# save clean data to csv ----------------------------------------------------------
write.csv(tube_temps, "output-data/tube_temps.csv", row.names = FALSE)
View(tube_temps)
View(tube_temps)
# script to extract and tidy tube temperatures csv
# libs ----------------------------------------------------------------------------
library(tidyverse)
# necessary data ------------------------------------------------------------------
months <- read_csv("raw-data/months.csv")
# function to extract data from url -----------------------------------------------
download_url <- function(url, fileext) {
tempdir <- tempdir()
path <- tempfile(tmpdir = tempdir, fileext = fileext)
download.file(url, destfile = path, mode = "wb")
path
}
# extract data --------------------------------------------------------------------
url <- "https://data.london.gov.uk/download/london-underground-average-monthly-temperatures/b01c7853-fff2-4781-9755-9b5e1404d78c/lu-average-monthly-temperatures.csv" # url for tube temp data download
tube_temps <- read_csv(download_url(url, ".csv"))
# data tidying --------------------------------------------------------------------
tube_temps %>%
left_join(months, by = "Month") %>%
mutate(date = as.Date(paste("01", month_num, Year, sep = "/"), "%d/%m/%Y")) %>%
select(-month_num) %>%
gather(Bakerloo:`Sub-surface_lines`, key = "tube", value = "temperature") %>%
mutate(tube = ifelse(tube == "Sub-surface_lines", "Sub-Surface Lines", tube)) %>%
mutate(tube = ifelse(tube == "Waterloo_and_City", "Waterloo and City", tube))
# save clean data to csv ----------------------------------------------------------
write.csv(tube_temps, "output-data/tube_temps.csv", row.names = FALSE)
# script to scrape and clean list of tube stations and lines
# initial scraping ---------------------------------------------------------------------------
URL <- "https://en.wikipedia.org/wiki/List_of_London_Underground_stations"
stations <- xml2::read_html(URL) %>%
rvest::html_node("body") %>%
rvest::html_node("table")
df_stations <- stations %>%
rvest::html_table() %>%
tibble::as_tibble()
# Where multiple lines are relevant for a station in the html table
# they are in seperate a tags
# Go back to the html
df_stations$line <- stations %>%
# Get the second column
rvest::html_nodes(xpath = "tbody/tr[*]/td[2]") %>%
# Map to keep cell data together (i.e., there might be 1 or more a tags per cell)
purrr::map(~ .x %>%
rvest::html_nodes(xpath = "a") %>%
# The line is in the title attribute
rvest::html_attr("title"))
df_stations <- df_stations %>%
select(Station, line) %>%
tidyr::unnest()
df_stations <- df_stations %>%
mutate(line = str_remove(line, " line")) %>%
mutate(line = str_remove(line, " \\(London Underground\\)"))
# write to csv -------------------------------------------------------------------------------
write.csv(df_stations, "output-data/tube_stations.csv", row.names = FALSE)
View(df_stations)
View(df_stations)
# script to clean passenger entries datastored in station-entry-and-exit-figures.xlsx file
# sheets in excel file -----------------------------------------------------------------------
passenger_num_sheets <- c("2017 Entry & Exit",
"2016 Entry & Exit",
"2015 Entry & Exit",
"2014 Entry & Exit",
"2013 Entry & Exit")
# function to extract and clean data from each sheet ------------------------------------------
station_entries <- function(sheet) { # function to extract the right data from each sheet
year = str_sub(sheet, 1, 4)
readxl::read_excel("../gov-data/station-entry-and-exit-figures.xlsx",
sheet = sheet,
skip = 6) %>%
select(station = "Station",
total = "million") %>%
mutate(year = year)
}
# map function to sheet -----------------------------------------------------------------------
station_numbers <- map_df(passenger_num_sheets, station_entries) %>%
filter(station != "Total") %>%
filter(!(is.na(station)))
# write as csv --------------------------------------------------------------------------------
write.csv(station_numbers, "output-data/station_numbers.csv", row.names = FALSE)
# script to clean passenger entries datastored in station-entry-and-exit-figures.xlsx file
# libs ---------------------------------------------------------------------------------------
library(tidyverse)
# sheets in excel file -----------------------------------------------------------------------
passenger_num_sheets <- c("2017 Entry & Exit",
"2016 Entry & Exit",
"2015 Entry & Exit",
"2014 Entry & Exit",
"2013 Entry & Exit")
# function to extract and clean data from each sheet ------------------------------------------
station_entries <- function(sheet) { # function to extract the right data from each sheet
year = str_sub(sheet, 1, 4)
readxl::read_excel("../raw-data/station-entry-and-exit-figures.xlsx",
sheet = sheet,
skip = 6) %>%
select(station = "Station",
total = "million") %>%
mutate(year = year)
}
# map function to sheet -----------------------------------------------------------------------
station_numbers <- map_df(passenger_num_sheets, station_entries) %>%
filter(station != "Total") %>%
filter(!(is.na(station)))
# write as csv --------------------------------------------------------------------------------
write.csv(station_numbers, "output-data/station_numbers.csv", row.names = FALSE)
# script to clean passenger entries datastored in station-entry-and-exit-figures.xlsx file
# libs ---------------------------------------------------------------------------------------
library(tidyverse)
# sheets in excel file -----------------------------------------------------------------------
passenger_num_sheets <- c("2017 Entry & Exit",
"2016 Entry & Exit",
"2015 Entry & Exit",
"2014 Entry & Exit",
"2013 Entry & Exit")
# function to extract and clean data from each sheet ------------------------------------------
station_entries <- function(sheet) { # function to extract the right data from each sheet
year = str_sub(sheet, 1, 4)
readxl::read_excel("raw-data/station-entry-and-exit-figures.xlsx",
sheet = sheet,
skip = 6) %>%
select(station = "Station",
total = "million") %>%
mutate(year = year)
}
# map function to sheet -----------------------------------------------------------------------
station_numbers <- map_df(passenger_num_sheets, station_entries) %>%
filter(station != "Total") %>%
filter(!(is.na(station)))
# write as csv --------------------------------------------------------------------------------
write.csv(station_numbers, "output-data/station_numbers.csv", row.names = FALSE)
View(station_numbers)
View(station_numbers)
View(tube_temps)
View(tube_temps)
# script to extract and tidy tube temperatures csv
# libs ----------------------------------------------------------------------------
library(tidyverse)
# necessary data ------------------------------------------------------------------
months <- read_csv("raw-data/months.csv")
# function to extract data from url -----------------------------------------------
download_url <- function(url, fileext) {
tempdir <- tempdir()
path <- tempfile(tmpdir = tempdir, fileext = fileext)
download.file(url, destfile = path, mode = "wb")
path
}
# extract data --------------------------------------------------------------------
url <- "https://data.london.gov.uk/download/london-underground-average-monthly-temperatures/b01c7853-fff2-4781-9755-9b5e1404d78c/lu-average-monthly-temperatures.csv" # url for tube temp data download
tube_temps <- read_csv(download_url(url, ".csv"))
# data tidying --------------------------------------------------------------------
tube_temps %>%
left_join(months, by = "Month") %>%
mutate(date = as.Date(paste("01", month_num, Year, sep = "/"), "%d/%m/%Y")) %>%
select(-month_num) %>%
gather(Bakerloo:`Sub-surface_lines`, key = "tube", value = "temperature") %>%
mutate(tube = ifelse(tube == "Sub-surface_lines", "Sub-Surface Lines", tube)) %>%
mutate(tube = ifelse(tube == "Waterloo_and_City", "Waterloo and City", tube))
# save clean data to csv ----------------------------------------------------------
write.csv(tube_temps, "output-data/tube_temps.csv", row.names = FALSE)
# script to extract and tidy tube temperatures csv
# libs ----------------------------------------------------------------------------
library(tidyverse)
# necessary data ------------------------------------------------------------------
months <- read_csv("raw-data/months.csv")
# function to extract data from url -----------------------------------------------
download_url <- function(url, fileext) {
tempdir <- tempdir()
path <- tempfile(tmpdir = tempdir, fileext = fileext)
download.file(url, destfile = path, mode = "wb")
path
}
# extract data --------------------------------------------------------------------
url <- "https://data.london.gov.uk/download/london-underground-average-monthly-temperatures/b01c7853-fff2-4781-9755-9b5e1404d78c/lu-average-monthly-temperatures.csv" # url for tube temp data download
tube_temps <- read_csv(download_url(url, ".csv"))
# data tidying --------------------------------------------------------------------
tube_temps <- tube_temps %>%
left_join(months, by = "Month") %>%
mutate(date = as.Date(paste("01", month_num, Year, sep = "/"), "%d/%m/%Y")) %>%
select(-month_num) %>%
gather(Bakerloo:`Sub-surface_lines`, key = "tube", value = "temperature") %>%
mutate(tube = ifelse(tube == "Sub-surface_lines", "Sub-Surface Lines", tube)) %>%
mutate(tube = ifelse(tube == "Waterloo_and_City", "Waterloo and City", tube))
# save clean data to csv ----------------------------------------------------------
write.csv(tube_temps, "output-data/tube_temps.csv", row.names = FALSE)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
model_3_data <- tube_temps %>%
mutate(subsurface = ifelse(tube == "Sub-Surface Lines", 1, 0))
model_3 <- lm(temperature ~ Year + Month + tube + subsurface:tube, data = tube_temps)
model_3_data <- tube_temps %>%
mutate(subsurface = ifelse(tube == "Sub-Surface Lines", 1, 0))
model_3 <- lm(temperature ~ Year + Month + tube + subsurface:tube, data = model_3_data)
summary(model_3)
model_3_data <- tube_temps %>%
mutate(subsurface = as.factor(ifelse(tube == "Sub-Surface Lines", 1, 0)))
model_3 <- lm(temperature ~ Year + Month + tube + subsurface:tube, data = model_3_data)
summary(model_3)
model_3_data <- tube_temps %>%
mutate(subsurface = as.factor(ifelse(tube == "Sub-Surface Lines", 1, 0)))
model_3 <- lm(temperature ~ Year + Month + tube + subsurface:Month, data = model_3_data)
summary(model_3)
hist(model_3$residuals, breaks = 50)
ols_plot_resid_qq(model_3)
library(olsrr)
hist(model_3$residuals, breaks = 50)
ols_plot_resid_qq(model_3)
ols_test_normality(model_3) # data much more normal
ols_plot_resid_fit(model_3)
View(model_3_data)
View(model_3_data)
# url for scraping -------------------------------------------------------------------------
URL <- "https://en.wikipedia.org/wiki/List_of_London_Underground_stations"
# scraping ---------------------------------------------------------------------------------
stations <- xml2::read_html(URL) %>%
html_node("body") %>%
html_node("table")
library(rvest)
library(xml2)
library(tidyverse)
# scraping ---------------------------------------------------------------------------------
stations <- read_html(URL) %>%
html_node("body") %>%
html_node("table")
df_stations <- stations %>%
html_table() %>%
as_tibble()
View(df_stations)
View(df_stations)
